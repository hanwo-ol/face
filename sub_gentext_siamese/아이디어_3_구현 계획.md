훌륭한 아이디어입니다. `data_combined.xlsx` (CSV) 파일은 이 실험에 완벽한 재료입니다.

얼굴 인식 실습에서 배운 `[입력 2개] -> [동일한 Base Network] -> [거리 계산]` 구조를 그대로 따르되, **이미지용 CNN**을 **텍스트용 RNN/LSTM**으로 교체하는 것이 핵심입니다.

다음은 이 아이디어를 코드로 구현하기 위한 단계별 계획표입니다.

-----

### AI 텍스트 판별 샴 네트워크: 단계별 개발 계획

#### 1단계: 환경 설정 및 데이터 로드

  * **목표:** 필요한 라이브러리를 임포트하고 제공된 `data_combined.xlsx` 파일을 로드합니다.
  * **세부 작업:**
      * `import pandas as pd`, `import numpy as np`, `import re`
      * `from tensorflow.keras.preprocessing.text import Tokenizer`
      * `from tensorflow.keras.preprocessing.sequence import pad_sequences`
      * `from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda, GRU`
      * `from tensorflow.keras.models import Model`
      * `import keras.ops as ops` (거리/손실 함수용)
      * `from sklearn.model_selection import train_test_split`
      * `pd.read_csv("C:\\Users\\...\\data_combined.xlsx")`로 데이터를 로드합니다. (이 파일은 실제로는 CSV 형식입니다)
      * `model` 열을 기준으로 'human' 텍스트와 'claude' (AI) 텍스트를 분리합니다.

#### 2단계: 데이터 쌍(Pair) 생성

  * **목표:** `(텍스트1, 텍스트2, 레이블)` 형태의 학습용 데이터 쌍을 만듭니다.
  * **세부 작업:**
    1.  `human_texts` 리스트와 `ai_texts` 리스트를 준비합니다.
    2.  **긍정 쌍 (Positive Pairs, Label = 1) 생성:**
          * `human_texts`에서 2개를 무작위로 뽑아 `(human_A, human_B)` 쌍을 만듭니다.
          * `ai_texts`에서 2개를 무작위로 뽑아 `(ai_C, ai_D)` 쌍을 만듭니다.
    3.  **부정 쌍 (Negative Pairs, Label = 0) 생성:**
          * `human_texts`에서 1개, `ai_texts`에서 1개를 무작위로 뽑아 `(human_A, ai_C)` 쌍을 만듭니다.
    4.  데이터 불균형을 맞추기 위해 긍정 쌍과 부정 쌍의 비율을 1:1로 생성합니다.
    5.  `pairs` 리스트(텍스트 쌍)와 `labels` 리스트(0 또는 1)를 최종적으로 만듭니다.
  * **[텍스트 데이터 쌍 구성 다이어그램]**

#### 3단계: 텍스트 전처리 및 토큰화

  * **목표:** 모든 텍스트를 정수 시퀀스로 변환하고 길이를 맞춥니다.
  * **세부 작업:**
    1.  간단한 텍스트 정제 함수를 만듭니다 (소문자화, 특수문자 일부 제거 등).
    2.  Keras의 `Tokenizer`를 초기화하고 모든 텍스트(`human_texts` + `ai_texts`)에 대해 `fit_on_texts`를 실행하여 '단어 사전'을 만듭니다. (`vocab_size` 결정)
    3.  `pairs` 리스트의 모든 텍스트를 `texts_to_sequences`로 변환합니다.
    4.  `pad_sequences`를 사용하여 모든 시퀀스의 길이를 동일하게 맞춥니다 (`MAX_LEN` 결정).
    5.  `pairs`는 이제 `(N, 2, MAX_LEN)` 형태의 NumPy 배열이 됩니다.

#### 4단계: 텍스트용 Base Network 구축

  * **목표:** 텍스트 시퀀스를 입력받아 '스타일 특징 벡터'를 출력하는 `base_network`를 만듭니다. (얼굴 인식 실습의 `build_base_network` 대체)
  * **[텍스트 임베딩을 위한 RNN/LSTM Base Network 구조]**
  * **세부 작업:**
    ```python
    def build_base_network_text(input_shape, vocab_size, embedding_dim=128, feature_dim=64):
        seq = Sequential()
        seq.add(Input(shape=input_shape))
        # 1. 단어를 임베딩 벡터로 변환 (이 층이 스타일을 학습)
        seq.add(Embedding(vocab_size, embedding_dim))
        # 2. 시퀀스 전체의 문맥/스타일을 하나의 벡터로 압축
        seq.add(LSTM(64)) # 또는 GRU(64)
        # 3. 최종 특징 벡터로 출력 (얼굴 인식의 50차원 벡터와 동일한 역할)
        seq.add(Dense(feature_dim, activation='relu'))
        return seq
    ```

#### 5단계: 샴 네트워크 모델 조립

  * **목표:** 두 개의 입력을 받아 `base_network`를 공유하고 거리를 계산하는 전체 모델을 조립합니다.
  * **세부 작업:** (이 부분은 얼굴 인식 실습 코드와 **거의 동일**합니다.)
    1.  `input_a = Input(shape=(MAX_LEN,))`
    2.  `input_b = Input(shape=(MAX_LEN,))`
    3.  `base_network = build_base_network_text(...)`
    4.  `feat_vecs_a = base_network(input_a)`
    5.  `feat_vecs_b = base_network(input_b)`
    6.  `euclidean_distance` 함수를 **실습에서 그대로 가져옵니다.** (`ops` 사용)
    7.  `distance = Lambda(euclidean_distance, ...)([feat_vecs_a, feat_vecs_b])`
    8.  `model = Model(inputs=[input_a, input_b], outputs=distance)`

#### 6단계: 모델 컴파일 및 학습 준비

  * **목표:** 손실 함수를 정의하고 모델을 컴파일하며, 데이터를 학습/검증용으로 분리합니다.
  * **세부 작업:**
    1.  `contrastive_loss` 함수를 **실습에서 그대로 가져옵니다.** (`ops` 사용)
    2.  `model.compile(loss=contrastive_loss, optimizer='rmsprop')`
    3.  `pairs`와 `labels`를 `train_test_split`을 사용하여 학습 세트와 테스트 세트로 분리합니다.
    4.  학습 세트 `pairs_train`을 `[pairs_train[:, 0], pairs_train[:, 1]]` (두 개의 입력)으로 분리합니다.

#### 7단계: 모델 학습 및 평가

  * **목표:** 모델을 학습시키고, 테스트 세트로 정확도를 평가합니다.
  * **세부 작업:**
    1.  `model.fit([pairs_train_1, pairs_train_2], labels_train, validation_split=0.2, ...)`
    2.  `pred = model.predict([pairs_test_1, pairs_test_2])`
    3.  `compute_accuracy` 함수를 **실습에서 그대로 가져옵니다.** (임계값 0.5 사용)
    4.  `compute_accuracy(pred, labels_test)`로 최종 정확도를 확인합니다.

이 계획대로 진행하면, 얼굴 인식에서 배운 구조를 재사용하면서도 텍스트의 '문체'를 구별하는 강력한 모델을 만들 수 있습니다.