샴 네트워크(Siamese Network) 원리를 적용한 AI 텍스트 판별 경량 모델 제안

목표: 얼굴 인식 실습에서 배운 핵심 원리(측정 학습, Metric Learning)를 텍스트 도메인에 적용하여, GPT 생성 텍스트와 인간 작성 텍스트를 구별하는 경량 모델을 구축한다.

어떻게 작동하는가? (얼굴 인식 vs 텍스트 판별)

구분

얼굴 인식 (실습 예제)

GPT vs Human 텍스트 판별 (아이디어)

목표

두 얼굴 이미지가 같은 사람인지 판별하는 "유사도 측정법" 학습

두 텍스트가 **같은 출처(스타일)**에서 왔는지 판별하는 "문체(Stylistic) 유사도 측정법" 학습

입력 데이터

얼굴 이미지 쌍 ($X_1, X_2$)

텍스트 쌍 ($X_1, X_2$)

레이블 (Y)

1 (Genuine): 같은 사람의 다른 사진



0 (Imposter): 다른 사람들의 사진

1 (Genuine Pair): Human-Human 쌍, GPT-GPT 쌍



0 (Imposter Pair): Human-GPT 쌍

Base Network

CNN (이미지 특징 추출기)

RNN, LSTM 또는 경량 Transformer (e.g., DistilBERT) (텍스트 특징/스타일 추출기)

학습 결과

'사람'을 구별하는 특징 공간 학습

'작성 스타일'을 구별하는 특징 공간 (임베딩 공간) 학습

학습 과정:

데이터 쌍 만들기 (가장 중요!):

긍정 쌍 (Positive Pairs, Y=1): 스타일이 유사한 쌍

[인간이 쓴 텍스트 A, 인간이 쓴 텍스트 B]

[GPT가 생성한 텍스트 C, GPT가 생성한 텍스트 D]

부정 쌍 (Negative Pairs, Y=0): 스타일이 다른 쌍

[인간이 쓴 텍스트 A, GPT가 생성한 텍스트 C]

모델 학습:

샴 네트워크는 대조 손실 함수(Contrastive Loss)를 통해 긍정 쌍의 텍스트 임베딩은 서로 가깝게, 부정 쌍의 텍스트 임베딩은 서로 멀게 만들도록 학습합니다.

결과적으로, 임베딩 공간에는 '인간 스타일 클러스터'와 'GPT 스타일 클러스터'가 자연스럽게 형성됩니다.

추론 (새로운 텍스트 판별) 과정:

기준점(Anchor) 설정: 미리 소수의 '확실한 인간 텍스트'와 '확실한 GPT 텍스트'를 임베딩하여 데이터베이스에 저장해 둡니다. (얼굴 인식 예제에서 데이터베이스에 저장된 단 한 장의 사진처럼)

새로운 텍스트 입력: 판별하고 싶은 새로운 텍스트가 들어오면, 학습된 Base Network에 통과시켜 임베딩 벡터를 추출합니다.

거리 계산: 이 새로운 벡터와 데이터베이스에 있는 기준점 벡터들 간의 거리를 모두 계산합니다.

판별:

'인간 텍스트' 기준점들과의 평균 거리가 더 가깝다면 -> "인간이 작성한 텍스트일 확률이 높다."

'GPT 텍스트' 기준점들과의 평균 거리가 더 가깝다면 -> "GPT가 생성한 텍스트일 확률이 높다."

이 접근법의 장점 (왜 흥미로운가?)

Few-shot Learning & 확장성: 이 모델의 가장 큰 장점입니다. 나중에 GPT-5나 Claude 같은 새로운 AI 모델이 등장했을 때, 그 모델이 생성한 텍스트 단 몇 개만 기준점으로 추가하면 모델 재학습 없이도 새로운 AI를 탐지할 수 있습니다. 일반 분류 모델은 새로운 클래스를 추가하려면 처음부터 다시 학습해야 합니다.

경량화 가능성: Base Network로 아주 가벼운 RNN 모델이나 작은 트랜스포머 모델을 사용하면, 추론 시 연산 부담이 적은 경량 모델을 만들 수 있습니다.

주제 불특정성(Topic-Agnostic): 모델은 텍스트의 '주제'가 아니라 '스타일'(문장 구조, 단어 선택의 미묘한 패턴 등)을 학습하도록 유도되므로, 특정 주제에 덜 편향될 수 있습니다.

고려해야 할 점 및 단점

데이터 쌍 구성의 어려움: '스타일이 유사한 인간 텍스트'를 어떻게 정의할 것인가가 중요합니다. 서로 다른 주제에 대해 쓴 글도 같은 사람의 글이라면 긍정 쌍으로 봐야 하는데, 모델이 주제의 유사성을 스타일의 유사성으로 착각하고 학습할 수 있습니다. 데이터 구성에 세심한 주의가 필요합니다.

간접적인 추론 방식: "이 텍스트는 GPT가 썼을 확률 95%입니다"라고 직접적인 확률을 출력하는 분류 모델과 달리, 기준점과의 거리를 비교하는 한 단계를 더 거쳐야 합니다.

확장: 다양한 AI 모델 데이터 포함의 중요성

샴 네트워크 아키텍처를 기반으로, 다양한 AI 모델이 생성한 텍스트를 구별하고 그 결과를 확률로 출력하는 경량 모델을 만들 수 있습니다.

그리고 여러 종류의 AI 생성 텍스트(GPT, Gemini, Claude, DeepSeek 등)를 데이터에 포함시키는 것은 모델의 능력을 극적으로 향상시키는 아주 중요한 전략입니다.

1. 확률을 뱉어내는 경량 모델 만들기 (재확인)

구조: 가중치를 공유하는 샴(Siamese) 인코더(e.g., 경량 RNN/Transformer) + 관계 벡터 생성기 + 확률을 출력하는 분류기 헤드(Dense + Sigmoid).

학습: (Human, AI) 쌍을 부정 쌍(0)으로, (Human, Human) 및 (AI, AI) 쌍을 긍정 쌍(1)으로 하여 이진 교차 엔트로피 손실(Binary Cross-Entropy Loss)로 학습.

출력: "두 텍스트의 출처(스타일)가 같을 확률은 $p$입니다."

2. 다양한 AI 모델 데이터를 포함시켰을 때 일어나는 일

여기가 바로 이 접근법의 진가가 드러나는 지점입니다. GPT, Gemini, Claude, DeepSeek 데이터를 모두 학습에 포함시키면, 모델은 단순히 'GPT vs Human'을 넘어 훨씬 더 일반적이고 강력한 능력을 갖추게 됩니다.

긍정적인 효과 (모델이 배우는 것)

'인공성(Artificiality)'이라는 일반적인 특징 학습:
모델은 특정 AI(GPT)의 언어 습관(e.g., "delve into...", "as a large language model...")을 암기하는 것을 넘어섭니다. 대신, 다양한 AI 모델들이 공통적으로 보이는 더 추상적이고 일반적인 '인공적인 글쓰기 스타일'의 특징을 학습하게 됩니다.

예를 들어, 일관되게 낮은 복잡도(Perplexity), 특정 문장 구조의 반복, 감정 표현의 부재, 과도하게 중립적인 톤 등의 특징을 포착할 수 있습니다.

결과적으로 임베딩 공간에는 거대한 **'AI 스타일 클러스터'**와 **'인간 스타일 클러스터'**가 형성됩니다.

강건성(Robustness) 및 일반화 성능 향상:
다양한 AI의 데이터를 학습했기 때문에, 이 모델은 **처음 보는 새로운 AI 모델(e.g., 미래에 나올 GPT-5)**이 생성한 텍스트를 만났을 때도 더 잘 탐지할 수 있습니다. 새로운 AI 역시 '인공성'의 특징을 공유할 가능성이 높기 때문에, 그 임베딩이 'AI 스타일 클러스터' 근처에 위치할 확률이 높습니다.

세분화된 판별 능력 (Sub-cluster 형성):
더 흥미로운 점은, 거대한 'AI 스타일 클러스터' 내부에 각 AI 모델별로 미묘하게 다른 **하위 클러스터(sub-cluster)**가 형성될 수 있다는 것입니다.

GPT 클러스터, Gemini 클러스터, Claude 클러스터 등이 서로 약간씩 다른 위치에 자리 잡게 됩니다.

이는 다음과 같은 고급 분석을 가능하게 합니다.

추론 시 가능한 시나리오

새로운 텍스트가 입력되었을 때, 우리는 그 텍스트의 임베딩을 계산한 후 다음과 같은 질문을 던질 수 있습니다.

질문 1: AI가 썼는가, 인간이 썼는가?

임베딩이 'AI 클러스터'와 '인간 클러스터' 중 어디에 더 가까운가?

예: [새로운 텍스트, 인간 기준 텍스트] 쌍의 유사도 확률 vs [새로운 텍스트, AI 기준 텍스트] 쌍의 유사도 확률

질문 2 (더 나아가): 어떤 AI가 썼을 가능성이 높은가?

임베딩이 'AI 클러스터' 내부에 있다면, 그 안에서 GPT 하위 클러스터, Gemini 하위 클러스터, Claude 하위 클러스터 중 어디에 가장 가까운가?

이를 통해 "이 텍스트는 AI가 작성했으며, 그중에서도 Gemini 스타일과 가장 유사합니다." 와 같은 더 상세한 추론이 가능해집니다.

결론

다양한 AI 모델의 생성 데이터를 포함시키는 것은, 샴 네트워크 기반 모델을 단순한 'GPT 탐지기'에서 '범용 AI 텍스트 스타일 분석기'로 진화시키는 핵심적인 단계입니다.

모델은 특정 AI의 '지문'을 찾는 것을 넘어, 'AI 글쓰기'와 '인간 글쓰기'의 근본적인 차이가 무엇인지에 대한 깊은 이해를 내재한 임베딩 공간을 구축하게 됩니다. 이는 모델의 정확도, 강건성, 그리고 미래 확장성을 모두 잡는 매우 강력한 전략입니다.